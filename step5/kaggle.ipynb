{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e4a146",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-11-06T13:41:16.037908Z",
     "iopub.status.busy": "2025-11-06T13:41:16.037612Z",
     "iopub.status.idle": "2025-11-06T13:41:17.901053Z",
     "shell.execute_reply": "2025-11-06T13:41:17.900113Z"
    },
    "papermill": {
     "duration": 1.870028,
     "end_time": "2025-11-06T13:41:17.902328",
     "exception": false,
     "start_time": "2025-11-06T13:41:16.032300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/deberta-v3-small/spm.model\n",
      "/kaggle/input/deberta-v3-small/config.json\n",
      "/kaggle/input/deberta-v3-small/README.md\n",
      "/kaggle/input/deberta-v3-small/tf_model.h5\n",
      "/kaggle/input/deberta-v3-small/tokenizer_config.json\n",
      "/kaggle/input/deberta-v3-small/gitattributes\n",
      "/kaggle/input/deberta-v3-small/pytorch_model.bin\n",
      "/kaggle/input/llm-classification-finetuning/sample_submission.csv\n",
      "/kaggle/input/llm-classification-finetuning/train.csv\n",
      "/kaggle/input/llm-classification-finetuning/test.csv\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/spm.model\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/trainer_state.json\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/training_args.bin\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/tokenizer.json\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/tokenizer_config.json\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/scaler.pt\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/scheduler.pt\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/model.safetensors\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/special_tokens_map.json\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/optimizer.pt\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/rng_state.pth\n",
      "/kaggle/input/final_2mlp_3epoch/pytorch/default/1/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d852eda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:41:17.911436Z",
     "iopub.status.busy": "2025-11-06T13:41:17.910750Z",
     "iopub.status.idle": "2025-11-06T13:42:00.885793Z",
     "shell.execute_reply": "2025-11-06T13:42:00.884901Z"
    },
    "papermill": {
     "duration": 42.980866,
     "end_time": "2025-11-06T13:42:00.887331",
     "exception": false,
     "start_time": "2025-11-06T13:41:17.906465",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 13:41:43.604676: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762436503.990600      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762436504.076960      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import Dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    modeling_outputs,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, log_loss\n",
    "from peft import get_peft_model, LoraConfig\n",
    "from torch.nn import functional as F\n",
    "from safetensors.torch import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3c0046b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:42:00.897026Z",
     "iopub.status.busy": "2025-11-06T13:42:00.896428Z",
     "iopub.status.idle": "2025-11-06T13:43:27.141582Z",
     "shell.execute_reply": "2025-11-06T13:43:27.140922Z"
    },
    "papermill": {
     "duration": 86.251042,
     "end_time": "2025-11-06T13:43:27.142651",
     "exception": false,
     "start_time": "2025-11-06T13:42:00.891609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: CUDA\n",
      "Using model: /kaggle/input/final_2mlp_3epoch/pytorch/default/1\n",
      "학습 데이터: 57477, 테스트 데이터: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/convert_slow_tokenizer.py:564: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd1843fde3f4a03bc401ce9284ac8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/57477 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9c69730b274561955820fe28449f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MODEL_NAME = \"/kaggle/input/final_2mlp_3epoch/pytorch/default/1\"\n",
    "MAX_LENGTH = 512\n",
    "BATCH_SIZE = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "EPOCHS = 3\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device.upper()}\")\n",
    "print(f\"Using model: {MODEL_NAME}\")\n",
    "\n",
    "try:\n",
    "    train_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/train.csv\")\n",
    "    test_df = pd.read_csv(\"/kaggle/input/llm-classification-finetuning/test.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"파일을 찾을 수 없습니다: {e}\")\n",
    "\n",
    "def create_target(row):\n",
    "    if row['winner_model_a'] == 1:\n",
    "        return 0  # Class 0: A wins\n",
    "    if row['winner_model_b'] == 1:\n",
    "        return 1  # Class 1: B wins\n",
    "    if row['winner_tie'] == 1:\n",
    "        return 2  # Class 2: Tie\n",
    "    return -1\n",
    "\n",
    "train_df['label'] = train_df.apply(create_target, axis=1)\n",
    "\n",
    "# train_data, val_data = train_test_split(train_df, test_size=0.1, random_state=42, stratify=train_df['label'])\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "# val_dataset = Dataset.from_pandas(val_data)\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "print(f\"학습 데이터: {len(train_dataset)}, 테스트 데이터: {len(test_dataset)}\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/deberta-v3-small\")\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    sep = tokenizer.sep_token\n",
    "    texts_a = [\n",
    "        f\"prompt: {p} {sep} response A: {a}\"\n",
    "        for p, a in zip(examples['prompt'], examples['response_a'])\n",
    "    ]\n",
    "    texts_b = [\n",
    "        f\"prompt: {p} {sep} response B: {b}\"\n",
    "        for p, b in zip(examples['prompt'], examples['response_b'])\n",
    "    ]\n",
    "\n",
    "    tokenized_a = tokenizer(\n",
    "        texts_a,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "    \n",
    "    tokenized_b = tokenizer(\n",
    "        texts_b,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LENGTH,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "    tokenized_inputs = {\n",
    "        'input_ids_a': tokenized_a['input_ids'],\n",
    "        'attention_mask_a': tokenized_a['attention_mask'],\n",
    "        'input_ids_b': tokenized_b['input_ids'],\n",
    "        'attention_mask_b': tokenized_b['attention_mask'],\n",
    "    }\n",
    "    if 'label' in examples:\n",
    "        tokenized_inputs[\"labels\"] = examples[\"label\"]\n",
    "\n",
    "    return tokenized_inputs\n",
    "\n",
    "tokenized_train = train_dataset.map(preprocess_function, batched=True, remove_columns=train_dataset.column_names)\n",
    "# tokenized_val = val_dataset.map(preprocess_function, batched=True, remove_columns=val_dataset.column_names)\n",
    "tokenized_test = test_dataset.map(preprocess_function, batched=True, remove_columns=test_dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "831e3fb8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T13:43:27.152768Z",
     "iopub.status.busy": "2025-11-06T13:43:27.152550Z",
     "iopub.status.idle": "2025-11-06T13:43:44.521311Z",
     "shell.execute_reply": "2025-11-06T13:43:44.520553Z"
    },
    "papermill": {
     "duration": 17.375151,
     "end_time": "2025-11-06T13:43:44.522394",
     "exception": false,
     "start_time": "2025-11-06T13:43:27.147243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2225: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 141,599,232 || trainable%: 0.2083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 설정 중...\n",
      "테스트 데이터 예측 중...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 예측 확률 Shape: (3, 3)\n",
      "제출 파일 'submission_step5_deberta_lora.csv' 생성이 완료되었습니다.\n",
      "        id  winner_model_a  winner_model_b  winner_tie\n",
      "0   136060        0.265920        0.274921    0.459158\n",
      "1   211333        0.299889        0.369827    0.330284\n",
      "2  1233961        0.225800        0.489133    0.285067\n"
     ]
    }
   ],
   "source": [
    "base_model = AutoModel.from_pretrained(\n",
    "    \"/kaggle/input/deberta-v3-small\",\n",
    "    device_map=device\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query_proj\", \"value_proj\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"none\",\n",
    ")\n",
    "\n",
    "peft_base_model = get_peft_model(base_model, lora_config)\n",
    "peft_base_model.print_trainable_parameters()\n",
    "\n",
    "class DeBERTaClassifier(torch.nn.Module):\n",
    "    def __init__(self, peft_model, num_labels=3):\n",
    "        super().__init__()\n",
    "        self.peft_model = peft_model\n",
    "        hidden_size = self.peft_model.config.hidden_size \n",
    "        self.num_labels = num_labels\n",
    "        self.cross_attn = torch.nn.ModuleList([\n",
    "            torch.nn.MultiheadAttention(\n",
    "                embed_dim=hidden_size,\n",
    "                num_heads=8,\n",
    "                dropout=0.1,\n",
    "                batch_first=True\n",
    "            ) for _ in range(6)\n",
    "        ])\n",
    "        \n",
    "        self.classifier_head = torch.nn.Sequential(\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(hidden_size * 2, hidden_size),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Dropout(0.1),\n",
    "            torch.nn.Linear(hidden_size, self.num_labels)\n",
    "        )\n",
    "\n",
    "    def forward(self, \n",
    "                input_ids_a=None, attention_mask_a=None, \n",
    "                input_ids_b=None, attention_mask_b=None, \n",
    "                labels=None):\n",
    "        \n",
    "        tokens_a = self.peft_model(\n",
    "            input_ids=input_ids_a,\n",
    "            attention_mask=attention_mask_a\n",
    "        ).last_hidden_state\n",
    "        \n",
    "        tokens_b = self.peft_model(\n",
    "            input_ids=input_ids_b,\n",
    "            attention_mask=attention_mask_b\n",
    "        ).last_hidden_state\n",
    "        \n",
    "        for cross_attn_layer in self.cross_attn:\n",
    "            attn_output_a, _ = cross_attn_layer(\n",
    "                query=tokens_a,\n",
    "                key=tokens_b,\n",
    "                value=tokens_b,\n",
    "                key_padding_mask=(attention_mask_b == 0)\n",
    "            )\n",
    "\n",
    "            attn_output_b, _ = cross_attn_layer(\n",
    "                query=tokens_b,\n",
    "                key=tokens_a,\n",
    "                value=tokens_a,\n",
    "                key_padding_mask=(attention_mask_a == 0)\n",
    "            )\n",
    "            tokens_a = attn_output_a\n",
    "            tokens_b = attn_output_b\n",
    "        \n",
    "        pooled_output_a = tokens_a[:, 0]\n",
    "        pooled_output_b = tokens_b[:, 0]\n",
    "        \n",
    "        combined_output = torch.cat((pooled_output_a, pooled_output_b), dim=1)\n",
    "        \n",
    "        logits = self.classifier_head(combined_output)\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = torch.nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1)) \n",
    "        \n",
    "        return modeling_outputs.SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=None,\n",
    "            attentions=None,\n",
    "        )\n",
    "\n",
    "model = DeBERTaClassifier(peft_base_model, num_labels=3).to(device)\n",
    "\n",
    "load_model(model, \"/kaggle/input/final_2mlp_3epoch/pytorch/default/1/model.safetensors\")\n",
    "class DualEncoderDataCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features):\n",
    "        \n",
    "        features_a = []\n",
    "        features_b = []\n",
    "        labels = []\n",
    "\n",
    "        for feature in features:\n",
    "            features_a.append({\n",
    "                'input_ids': feature['input_ids_a'],\n",
    "                'attention_mask': feature['attention_mask_a']\n",
    "            })\n",
    "            features_b.append({\n",
    "                'input_ids': feature['input_ids_b'],\n",
    "                'attention_mask': feature['attention_mask_b']\n",
    "            })\n",
    "            if 'labels' in feature:\n",
    "                labels.append(feature['labels'])\n",
    "\n",
    "        batch_a = self.tokenizer.pad(\n",
    "            features_a,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        \n",
    "        batch_b = self.tokenizer.pad(\n",
    "            features_b,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        batch = {\n",
    "            'input_ids_a': batch_a['input_ids'],\n",
    "            'attention_mask_a': batch_a['attention_mask'],\n",
    "            'input_ids_b': batch_b['input_ids'],\n",
    "            'attention_mask_b': batch_b['attention_mask'],\n",
    "        }\n",
    "\n",
    "        if labels:\n",
    "            batch['labels'] = torch.tensor(labels, dtype=torch.long)\n",
    "            \n",
    "        return batch\n",
    "    \n",
    "dual_collator = DualEncoderDataCollator(tokenizer=tokenizer)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    probs = F.softmax(torch.tensor(logits), dim=-1).numpy()\n",
    "    epsilon = 1e-15\n",
    "    probs = np.clip(probs, epsilon, 1 - epsilon)\n",
    "    logloss = log_loss(labels, probs)\n",
    "    return {\"loss\": logloss}\n",
    "\n",
    "\n",
    "print(\"Trainer 설정 중...\")\n",
    "infer_args = TrainingArguments(\n",
    "    output_dir=\"./infer_results\",\n",
    "    per_device_eval_batch_size=BATCH_SIZE,\n",
    "    report_to=\"none\",\n",
    "    fp16=(device == 'cuda') # GPU 사용 시 fp16 활성화\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=infer_args,\n",
    "    data_collator=dual_collator\n",
    "    # tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "# print(\"--- 학습 시작 ---\")\n",
    "# trainer.train()\n",
    "# print(\"--- 학습 완료 ---\")\n",
    "\n",
    "# --- 6. 테스트 데이터 예측 및 제출 ---\n",
    "print(\"테스트 데이터 예측 중...\")\n",
    "predictions = trainer.predict(tokenized_test)\n",
    "\n",
    "# Logits -> Probabilities\n",
    "test_logits = predictions.predictions\n",
    "test_probs = F.softmax(torch.tensor(test_logits), dim=-1).numpy()\n",
    "\n",
    "print(f\"테스트 예측 확률 Shape: {test_probs.shape}\")\n",
    "\n",
    "# 제출 파일 생성\n",
    "submission_df = pd.DataFrame({'id': test_df['id']})\n",
    "submission_df['winner_model_a'] = test_probs[:, 0] # Class 0\n",
    "submission_df['winner_model_b'] = test_probs[:, 1] # Class 1\n",
    "submission_df['winner_tie']     = test_probs[:, 2] # Class 2\n",
    "\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "print(\"제출 파일 'submission_step5_deberta_lora.csv' 생성이 완료되었습니다.\")\n",
    "print(submission_df.head())"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9809560,
     "isSourceIdPinned": false,
     "sourceId": 86518,
     "sourceType": "competition"
    },
    {
     "datasetId": 8667253,
     "sourceId": 13635866,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": false,
     "modelId": 492218,
     "modelInstanceId": 476299,
     "sourceId": 631922,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 156.6687,
   "end_time": "2025-11-06T13:43:47.609280",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-06T13:41:10.940580",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0b05e6e052fd4d2798f998608c5b1222": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d669c0ae875f454ab417b467b2f84856",
       "placeholder": "​",
       "style": "IPY_MODEL_e90fdc405bca43e0b28e09a460c92bf7",
       "tabbable": null,
       "tooltip": null,
       "value": " 57477/57477 [01:18&lt;00:00, 731.96 examples/s]"
      }
     },
     "1260513a796840618207099beda352a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1b75d3ef1fc649cabae3d24f767fb81d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "44bdd6cccf9c4d18a09c294929c1b221": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4f9c69730b274561955820fe28449f48": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_a7076616a1ef4956bfa02d7ea011c885",
        "IPY_MODEL_ccbf08b30f3940f88f85896951f1dd59",
        "IPY_MODEL_7d09c5bfb78d4f49877936c947c1a810"
       ],
       "layout": "IPY_MODEL_b10bd2185312460bb51edd26dc778289",
       "tabbable": null,
       "tooltip": null
      }
     },
     "545a920fa0a543b0801ee358a17dc2d0": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5b5d8483bb114ed2833c7b62d0977ce4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d011959a7cea4b5f8ec4298350679b97",
       "placeholder": "​",
       "style": "IPY_MODEL_44bdd6cccf9c4d18a09c294929c1b221",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "670c1d68e6344087a10d44babbc08e4c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d09c5bfb78d4f49877936c947c1a810": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_670c1d68e6344087a10d44babbc08e4c",
       "placeholder": "​",
       "style": "IPY_MODEL_b768add28c3a47a78db00f11223052d1",
       "tabbable": null,
       "tooltip": null,
       "value": " 3/3 [00:00&lt;00:00, 136.08 examples/s]"
      }
     },
     "7e400ae3c0164d298bbcd726fecc9fcf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8022fdf3825d437c99c3a1d2013b4731": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "90ab2c221fe14bc69e9403c4d04cd7a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_b195763da25e4a5ab0fede9976bc61b1",
       "max": 57477,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_7e400ae3c0164d298bbcd726fecc9fcf",
       "tabbable": null,
       "tooltip": null,
       "value": 57477
      }
     },
     "9494b62e21a643be875146ba3b98f6fd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "a7076616a1ef4956bfa02d7ea011c885": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9494b62e21a643be875146ba3b98f6fd",
       "placeholder": "​",
       "style": "IPY_MODEL_1b75d3ef1fc649cabae3d24f767fb81d",
       "tabbable": null,
       "tooltip": null,
       "value": "Map: 100%"
      }
     },
     "b10bd2185312460bb51edd26dc778289": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b195763da25e4a5ab0fede9976bc61b1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b768add28c3a47a78db00f11223052d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ccbf08b30f3940f88f85896951f1dd59": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8022fdf3825d437c99c3a1d2013b4731",
       "max": 3,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1260513a796840618207099beda352a5",
       "tabbable": null,
       "tooltip": null,
       "value": 3
      }
     },
     "d011959a7cea4b5f8ec4298350679b97": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d669c0ae875f454ab417b467b2f84856": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e90fdc405bca43e0b28e09a460c92bf7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "efd1843fde3f4a03bc401ce9284ac8ae": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_5b5d8483bb114ed2833c7b62d0977ce4",
        "IPY_MODEL_90ab2c221fe14bc69e9403c4d04cd7a2",
        "IPY_MODEL_0b05e6e052fd4d2798f998608c5b1222"
       ],
       "layout": "IPY_MODEL_545a920fa0a543b0801ee358a17dc2d0",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
