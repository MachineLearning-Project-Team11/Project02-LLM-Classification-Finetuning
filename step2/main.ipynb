{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca1c9d8f",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1762103751376,
     "user": {
      "displayName": "김현수",
      "userId": "02831780464337922222"
     },
     "user_tz": -540
    },
    "id": "ca1c9d8f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcff527",
   "metadata": {
    "id": "4dcff527"
   },
   "source": [
    "# Step 2. Embedding-based Model\n",
    "- Use a pre-trained sentence embedding model (e.g., MiniLM, E5).\n",
    "- Construct prompt+response embeddings and train a classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e54d1e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772,
     "referenced_widgets": [
      "2645782ef6a64bfba0d5f935f3cb21f1",
      "bbbcf5af2b9641d0b694255f48fc884f",
      "47bcdf4eac5e41d6a1f836f9bea94db9",
      "0e5c68dae42648bfb60d04d40aed9e4b",
      "722af99b97c841da942a81533a00bf4c",
      "4981948fe2d64304bb3e296ddb36bc31",
      "e852bac872f94f7a9c7f6ba92262b0c5",
      "c73ffde8d5fe48308b178d07730ece36",
      "70d182f6417d4bacb34552886fc2a871",
      "9b89c9e71fa34da488e6639e9bc58ccf",
      "247eeae9ea234d7fa55e95627706c9f4",
      "7e32709fb68a4f10857719d586b3464c",
      "5ed92227aaf9459885e9045c8539fcc1",
      "276817c5d92646c89fe3a821018b8af8",
      "00a9f8821b7548568e125d62c488d3f0",
      "f9dd854a6411473b94f59d46bd111e45",
      "0ab3e1dc7d604768a4ace05843a0b6c8",
      "48c20edcb2394842b0df4571dba93911",
      "351cc0f2da3540669099e0959c67e5f3",
      "1693144cd00242baa5058c3ffc0dae32",
      "77eb26c819bc4d859a19b28ed58c747b",
      "0c4ca18fe9e0471c83870c89bdbf4cf4",
      "30d5fce2caa94b37ac720a0801e19ef8",
      "e1bcb5c6da88470fbf70d62037d7902c",
      "bbf1c44b2c7a4449a20e1794d3151322",
      "1dc9855b25f549c6891083a5998ab866",
      "76c2641b4c5e4c2f963b253b766cd278",
      "089c4bf41fd84e36a4642cc3416562a2",
      "d26a6d2263c84c27a414e2f5c0338afa",
      "4aebaa7c90ea4dcdbcba7484fa3b0376",
      "bbfa36e19bd9481eaf1b4b814101dacd",
      "fdb9a345e6ae419b97f939a868fca066",
      "1a34cd3e88974d5eb2807445dcdae312",
      "91b6c4c7ac5e45739f1e5c5de5db2037",
      "1a5b3bccfab14a9a8a765664339cb92e",
      "de3d221b7685454ebe7d91e4b7896126",
      "aac854364b20443ca0075c9a4401cb7c",
      "8d514a4f9334439dbb10d1e4f3ef1ef6",
      "7a1a6fbde6664e01b3cfe91ae67ffc94",
      "fc0d30608f7d49deae7d4f592cc75190",
      "466ce85c47664051a38fe76b5b1f0713",
      "3590326f40eb4bb8874c260180a0b04e",
      "2998856f05474d41b5d10b4a33fa068d",
      "88006876f3654f9b9d336f1459713335"
     ]
    },
    "executionInfo": {
     "elapsed": 450505,
     "status": "ok",
     "timestamp": 1762106222304,
     "user": {
      "displayName": "김현수",
      "userId": "02831780464337922222"
     },
     "user_tz": -540
    },
    "id": "e1e54d1e",
    "outputId": "e07ce443-1354-4664-dda2-0ee020d59996"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target class distribution:\n",
      "y_target\n",
      "0    0.349079\n",
      "1    0.341911\n",
      "2    0.309011\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e68c222cc974f9da4d9062c1c031e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CAU\\anaconda3\\envs\\proj\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\CAU\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b9a46d88024d01a5fdad4b5747efa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca28f4164f2345068bc2f0c7853d9b0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50f707c0f3cd460f9192c4cf0fa647ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b8a5dd306b4195aba09522bbf8873c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9324519ab17a45459297c566ff1771f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2381f39b510f4a7589a72bd7e8c0d42b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f05bbc1d1844909e4e0e26a767b136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50a0a4477ca54d8cbd37c37ce49ee564",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaafa01eed294a499ada0fd04241c349",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a821cbc977425eaccee37322433891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0207b9afc4664873b71389588e713f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e1d6b0b3c90499d9e3d49f98c65a50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/225 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding A Shape: (57477, 384)\n",
      "embedding B Shape: (57477, 384)\n",
      "Final feature vector Shape: (57477, 768)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b25b8ef74c0c4e7c98ad5b02f59a59b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b1d4dc027c4a6aa94168d200f9d4d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding A Shape: (3, 384)\n",
      "embedding B Shape: (3, 384)\n",
      "Final feature vector Shape: (3, 768)\n",
      "Validation (Embedding Features)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CAU\\anaconda3\\envs\\proj\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DATA (Multiclass) Log Loss: 1.0637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\CAU\\anaconda3\\envs\\proj\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1272: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.8. From then on, it will always use 'multinomial'. Leave it to its default value to avoid this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 확률 배열 shape: (3, 3)\n",
      "Create Submission Completed\n",
      "        id  winner_model_a  winner_model_b  winner_tie\n",
      "0   136060        0.273443        0.193083    0.533474\n",
      "1   211333        0.265360        0.435535    0.299104\n",
      "2  1233961        0.242280        0.474682    0.283037\n",
      "\n",
      "Sum of first prediction: 1.0\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_df = pd.read_csv(\"./data/train.csv\")\n",
    "    test_df = pd.read_csv(\"./data/test.csv\")\n",
    "    sample_submission_df = pd.read_csv(\"./data/sample_submission.csv\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"File Not Found: {e}\")\n",
    "\n",
    "\n",
    "def create_target(row):\n",
    "    if row['winner_model_a'] == 1:\n",
    "        return 0  # Class 0: A wins\n",
    "    if row['winner_model_b'] == 1:\n",
    "        return 1  # Class 1: B wins\n",
    "    if row['winner_tie'] == 1:\n",
    "        return 2  # Class 2: Tie\n",
    "    return -1\n",
    "\n",
    "\n",
    "train_df['y_target'] = train_df.apply(create_target, axis=1)\n",
    "y = train_df['y_target']\n",
    "\n",
    "print(f\"target class distribution:\\n{y.value_counts(normalize=True)}\")\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2', device='cuda')\n",
    "\n",
    "def create_embedding_features(df, model):\n",
    "\n",
    "    texts_a = (df['prompt'] + \" [SEP] \" + df['response_a']).tolist()\n",
    "    texts_b = (df['prompt'] + \" [SEP] \" + df['response_b']).tolist()\n",
    "\n",
    "    embeddings_a = model.encode(texts_a, show_progress_bar=True, batch_size=256)\n",
    "    embeddings_b = model.encode(texts_b, show_progress_bar=True, batch_size=256)\n",
    "\n",
    "    print(f\"embedding A Shape: {embeddings_a.shape}\")\n",
    "    print(f\"embedding B Shape: {embeddings_b.shape}\")\n",
    "\n",
    "    X = np.concatenate([embeddings_a, embeddings_b], axis=1)\n",
    "\n",
    "    print(f\"Final feature vector Shape: {X.shape}\")\n",
    "    return X\n",
    "\n",
    "X = create_embedding_features(train_df, model)\n",
    "X_test = create_embedding_features(test_df, model)\n",
    "\n",
    "print(\"Validation (Embedding Features)\")\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        random_state=42,\n",
    "        max_iter=2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "val_preds_proba = model.predict_proba(X_val)\n",
    "val_logloss = log_loss(y_val, val_preds_proba)\n",
    "print(f\"Validation DATA (Multiclass) Log Loss: {val_logloss:.4f}\")\n",
    "\n",
    "model = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LogisticRegression(\n",
    "        multi_class='multinomial',\n",
    "        solver='lbfgs',\n",
    "        random_state=42,\n",
    "        max_iter=2000\n",
    "    ))\n",
    "])\n",
    "\n",
    "model.fit(X, y)\n",
    "\n",
    "test_preds_proba = model.predict_proba(X_test)\n",
    "\n",
    "print(f\"예측 확률 배열 shape: {test_preds_proba.shape}\")\n",
    "\n",
    "submission_df = pd.DataFrame({'id': test_df['id']})\n",
    "\n",
    "submission_df['winner_model_a'] = test_preds_proba[:, 0]\n",
    "submission_df['winner_model_b'] = test_preds_proba[:, 1]\n",
    "submission_df['winner_tie'] = test_preds_proba[:, 2]\n",
    "\n",
    "\n",
    "submission_df.to_csv(f\"submission.csv\", index=False)\n",
    "\n",
    "print(\"Create Submission Completed\")\n",
    "print(submission_df.head())\n",
    "\n",
    "print(\"\\nSum of first prediction:\", submission_df.iloc[0][['winner_model_a', 'winner_model_b', 'winner_tie']].sum())"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
